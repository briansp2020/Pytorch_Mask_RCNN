{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"lib/roi_align\")\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from config import Config\n",
    "from network.mask_rcnn import MaskRCNN\n",
    "from postprocess import visualize\n",
    "from tasks.merge_task import final_detections, unmold_detections\n",
    "from preprocess.InputProcess import (compose_image_meta, mold_image,\n",
    "                                     mold_inputs, parse_image_meta,\n",
    "                                     resize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "class InferenceConfig(Config):\n",
    "\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco\"\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 80  # COCO has 80 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_variable(numpy_data, volatile=False):\n",
    "    numpy_data = numpy_data.astype(np.float32)\n",
    "    torch_data = torch.from_numpy(numpy_data).float()\n",
    "    variable = Variable(torch_data, volatile=volatile)\n",
    "    return variable\n",
    "\n",
    "\n",
    "def run_demo(image_path, save_path, model):\n",
    "    start = time.time()\n",
    "    oriImg = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(oriImg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    molded_image, image_metas, windows = mold_inputs([image], config)\n",
    "\n",
    "    inputs = molded_image.transpose((0, 3, 1, 2))\n",
    "    inputs = torch.from_numpy(inputs).float()\n",
    "    inputs = Variable(inputs, volatile=True).cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    rpn_class_logits, rpn_class, rpn_bbox,\\\n",
    "        rpn_rois, mrcnn_class_logits, mrcnn_class,\\\n",
    "        mrcnn_bbox, mrcnn_masks_logits = outputs\n",
    "\n",
    "    mrcnn_class = mrcnn_class.cpu().data.numpy()\n",
    "    mrcnn_bbox = mrcnn_bbox.cpu().data.numpy()\n",
    "\n",
    "    rois = rpn_rois.cpu().data.numpy() / 1024.\n",
    "    rois = rois[:, :, [1, 0, 3, 2]]\n",
    "\n",
    "    detections = final_detections(\n",
    "        rois, mrcnn_class, mrcnn_bbox, image_metas, config)\n",
    "\n",
    "    mask_rois = detections[..., :4][..., [1, 0, 3, 2]]\n",
    "    mask_rois = to_variable(mask_rois, volatile=True).cuda()\n",
    "\n",
    "    mrcnn_mask = model.rpn_mask(model.mrcnn_feature_maps, mask_rois)\n",
    "\n",
    "    mrcnn_mask = F.sigmoid(mrcnn_mask)\n",
    "    mrcnn_mask = mrcnn_mask.cpu().data.numpy()\n",
    "    mrcnn_mask = mrcnn_mask.transpose(0, 1, 3, 4, 2)\n",
    "\n",
    "    final_rois, final_class_ids, final_scores, final_masks =\\\n",
    "        unmold_detections(detections[0], mrcnn_mask[0],\n",
    "                          oriImg.shape, windows[0])\n",
    "    \n",
    "    reslut = {\n",
    "        \"rois\": final_rois,\n",
    "        \"class_ids\": final_class_ids,\n",
    "        \"scores\": final_scores,\n",
    "        \"masks\": final_masks,\n",
    "    }\n",
    "    visualize.display_instances(image, reslut['rois'], reslut['masks'], reslut['class_ids'],\n",
    "                                class_names, save_path, reslut['scores'])\n",
    "    end = time.time()\n",
    "    print('spend time', end - start)\n",
    "\n",
    "\n",
    "def directory_demo(image_source_path, image_save_path, model):\n",
    "\n",
    "    images = os.listdir(image_source_path)\n",
    "\n",
    "    for i, image_path in enumerate(images):\n",
    "        if i % 10 == 0:\n",
    "            print('Processed %d images' % i)\n",
    "        one_source_path = os.path.join(image_source_path, image_path)\n",
    "        one_save_path = os.path.join(\n",
    "            image_save_path, image_path).rsplit('.', 1)[0] + '.png'\n",
    "        run_demo(one_source_path, one_save_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        500\n",
      "POST_NMS_ROIS_TRAINING         500\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "resnet spend 0.7928314208984375\n",
      "fpn spend 1 1.5874526500701904\n",
      "first roalign 0.013176441192626953\n",
      "spend time 7.542646408081055\n"
     ]
    }
   ],
   "source": [
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "pretrained_weight = \"./mrcnn.pth\"\n",
    "state_dict = torch.load(pretrained_weight)\n",
    "\n",
    "model = MaskRCNN(config=config, mode='inference')\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "image_path = 'README/santas.jpg'\n",
    "save_path = 'README/santas_output.png'\n",
    "run_demo(image_path, save_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
